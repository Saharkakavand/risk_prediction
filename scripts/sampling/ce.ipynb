{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Goals:\n",
    "- understand cross entropy method\n",
    "- understand main challenges in using it for IS\n",
    "- understand challenges in doing active learning\n",
    "Plan:\n",
    "- fit a network to some dataset \n",
    "- fit it again using some other method\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "def gaussian_pdf(x, mu=0, sigma=1):\n",
    "    return 1/np.sqrt(2 * sigma ** 2 * np.pi) * np.exp(-(x - mu) ** 2 / (2 * sigma ** 2))\n",
    "\n",
    "def logistic(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def gen_1d_data(gen, xmin, xmax, num_samples):\n",
    "    x = np.linspace(xmin, xmax, num_samples)\n",
    "    return (x.reshape(-1,1), gen(x).reshape(-1,1))    \n",
    "\n",
    "def init_toy_data(batch_size, input_dim, output_dim):\n",
    "    np.random.seed(1)\n",
    "    X = 10 * np.random.randn(batch_size, input_dim)\n",
    "    y = np.random.randn(batch_size, output_dim)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x10673cd68>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFjH0JalF/j/Y/JcUWSdrJQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1065c6198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_samples = 10\n",
    "x, y = gen_1d_data(gaussian_pdf, -3, 3, num_samples)\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class basic_nnet(object):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.initialize_params()\n",
    "        \n",
    "    def initialize_params(self):\n",
    "        # input to hidden \n",
    "        w_1 = np.random.randn(self.input_dim, self.hidden_dim)\n",
    "        b_1 = np.zeros((1, self.hidden_dim)) + .01\n",
    "        \n",
    "        # hidden to hidden\n",
    "        w_2 = np.random.randn(self.hidden_dim, self.hidden_dim)\n",
    "        b_2 = np.zeros((1, self.hidden_dim)) + .01\n",
    "        \n",
    "        # hidden to output\n",
    "        w_3 = np.random.randn(self.hidden_dim, self.output_dim)\n",
    "        b_3 = np.zeros((1, self.output_dim))\n",
    "        \n",
    "        self.params = {'w_1': w_1, 'b_1': b_1, \n",
    "                       'w_2': w_2, 'b_2': b_2,\n",
    "                       'w_3': w_3, 'b_3': b_3}\n",
    "        \n",
    "    def loss(self, X, y=None):\n",
    "        w_1, b_1 = self.params['w_1'], self.params['b_1'] \n",
    "        w_2, b_2 = self.params['w_2'], self.params['b_2']\n",
    "        w_3, b_3 = self.params['w_3'], self.params['b_3']\n",
    "        \n",
    "        # input to hidden\n",
    "        h_1 = np.maximum(0, np.dot(X, w_1) + b_1)\n",
    "        h_2 = np.maximum(0, np.dot(h_1, w_2) + b_2)\n",
    "        \n",
    "        # hidden to output\n",
    "        scores = np.dot(h_2, w_3) + b_3\n",
    "        \n",
    "        # if y not provided, then just return scores\n",
    "        if y is None:\n",
    "            return scores\n",
    "        \n",
    "        # loss \n",
    "        loss = .5 * np.sum((scores - y) ** 2)\n",
    "        \n",
    "        # grads\n",
    "        dloss_dscores = (scores - y)\n",
    "        dscores_db_3 = np.sum(dloss_dscores, axis=0, keepdims=True)\n",
    "        dscores_dw_3 = np.dot(h_2.T, dloss_dscores)\n",
    "        dscores_dh2 = np.dot(dloss_dscores, w_3.T)\n",
    "        \n",
    "        dh_2_dz_2 = dscores_dh2[:]\n",
    "        dh_2_dz_2[h_2 <= 0] = 0\n",
    "        dz_2_db_2 = np.sum(dh_2_dz_2, axis=0, keepdims=True)\n",
    "        dz_2_dw_2 = np.dot(h_1.T, dh_2_dz_2)\n",
    "        dz_2_dh_1 = np.dot(dh_2_dz_2, w_2.T)\n",
    "        \n",
    "        dh_1_dz_1 = dz_2_dh_1[:]\n",
    "        dh_1_dz_1[h_1 <= 0] = 0\n",
    "        dz_1_db_1 = np.sum(dh_1_dz_1, axis=0, keepdims=True)\n",
    "        dz_1_dw_1 = np.dot(X.T, dh_1_dz_1)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['w_1'] = dz_1_dw_1\n",
    "        grads['b_1'] = dz_1_db_1\n",
    "        grads['w_2'] = dz_2_dw_2\n",
    "        grads['b_2'] = dz_2_db_2\n",
    "        grads['w_3'] = dscores_dw_3\n",
    "        grads['b_3'] = dscores_db_3\n",
    "        \n",
    "        return loss, grads\n",
    "    \n",
    "    def train(self, X, y, lr=0.001, batch_size=10, num_epochs=10, lr_decay=.999, verbose=True):\n",
    "        \n",
    "        # train for epochs\n",
    "        for epoch in range(num_epochs):\n",
    "            \n",
    "            # determine batches\n",
    "            num_batches = int(len(X) / batch_size)\n",
    "            if num_batches < len(X) / batch_size:\n",
    "                num_batches += 1\n",
    "            \n",
    "            losses = []\n",
    "            for bidx in range(num_batches):\n",
    "                \n",
    "                # compute loss and grads on this batch\n",
    "                s = bidx * batch_size\n",
    "                e = s + batch_size\n",
    "                loss, grads = self.loss(X[s:e], y[s:e])\n",
    "                losses.append(loss)\n",
    "                \n",
    "                # perform gradient descent update\n",
    "                for k in self.params.keys():\n",
    "                    self.params[k] -= lr * grads[k]\n",
    "            \n",
    "            # lr update\n",
    "            lr *= lr_decay\n",
    "            \n",
    "            # how's it goin?\n",
    "            if verbose and epoch % 100 == 0:\n",
    "                print('epoch: {} / {}\\t loss: {}'.format(epoch, num_epochs, np.mean(losses)))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def eval_numerical_gradient(f, x, verbose=True, h=0.00001):\n",
    "    \"\"\" \n",
    "    - f should be a function that takes a single argument\n",
    "    - x is the point (numpy array) to evaluate the gradient at\n",
    "    \"\"\" \n",
    "    fx = f(x) # evaluate function value at original point\n",
    "    grad = np.zeros_like(x)\n",
    "    # iterate over all indexes in x\n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "        # evaluate function at x+h\n",
    "        ix = it.multi_index\n",
    "        oldval = x[ix]\n",
    "        x[ix] = oldval + h # increment by h\n",
    "        fxph = f(x) # evalute f(x + h)\n",
    "        x[ix] = oldval - h\n",
    "        fxmh = f(x) # evaluate f(x - h)\n",
    "        x[ix] = oldval # restore\n",
    "\n",
    "        # compute the partial derivative with centered formula\n",
    "        grad[ix] = (fxph - fxmh) / (2 * h) # the slope\n",
    "        if verbose:\n",
    "            print(ix, grad[ix])\n",
    "        it.iternext() # step to next dimension\n",
    "    return grad\n",
    "\n",
    "def rel_error(x, y):\n",
    "    \"\"\" returns relative error \"\"\"\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b_1 max relative error: 6.401469e-10\n",
      "b_2 max relative error: 1.344131e-10\n",
      "w_1 max relative error: 5.726133e-12\n",
      "w_2 max relative error: 1.749904e-11\n",
      "w_3 max relative error: 3.472208e-12\n",
      "b_3 max relative error: 2.122496e-10\n"
     ]
    }
   ],
   "source": [
    "input_dim, hidden_dim, output_dim, batch_size = 1, 2, 1, 2\n",
    "net = basic_nnet(input_dim, hidden_dim, output_dim)\n",
    "X, y = init_toy_data(batch_size, input_dim, output_dim)\n",
    "loss, grads = net.loss(X, y)\n",
    "\n",
    "# these should all be less than 1e-8 or so\n",
    "for param_name in grads.keys():\n",
    "    \n",
    "    f = lambda W: net.loss(X, y)[0]\n",
    "    param_grad_num = eval_numerical_gradient(f, net.params[param_name], verbose=False)\n",
    "    print('%s max relative error: %e' % (param_name, rel_error(param_grad_num, grads[param_name])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "input_dim, hidden_dim, output_dim, batch_size = 1, 16, 1, 200\n",
    "net = basic_nnet(input_dim, hidden_dim, output_dim)\n",
    "X, y = gen_1d_data(logistic, -3, 3, num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 / 1000\t loss: 0.000354581948040594\n",
      "epoch: 100 / 1000\t loss: 0.0006510606897542087\n",
      "epoch: 200 / 1000\t loss: 0.0006191346823571936\n",
      "epoch: 300 / 1000\t loss: 0.0005842560835957554\n",
      "epoch: 400 / 1000\t loss: 0.0005584043479705025\n",
      "epoch: 500 / 1000\t loss: 0.0005438264347901942\n",
      "epoch: 600 / 1000\t loss: 0.0005334860469525473\n",
      "epoch: 700 / 1000\t loss: 0.0005281317793502976\n",
      "epoch: 800 / 1000\t loss: 0.0005247175118308653\n",
      "epoch: 900 / 1000\t loss: 0.0005227208728861159\n"
     ]
    }
   ],
   "source": [
    "net.train(X, y, lr=.001, num_epochs=1000, lr_decay=.995, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x108991da0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwh0AEvT/TIx5movcWRMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108458898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-3,3,num_samples).reshape(-1,1)\n",
    "y_pred = net.loss(x)\n",
    "plt.subplot('121')\n",
    "plt.scatter(x, y_pred)\n",
    "plt.subplot('122')\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ok it kinda of works now what?\n",
    "- see how many samples to get good loss?\n",
    "- \n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
